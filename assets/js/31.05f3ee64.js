(window.webpackJsonp=window.webpackJsonp||[]).push([[31],{360:function(t,a,s){"use strict";s.r(a);var i=s(0),e=Object(i.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[t._v("随着时代的发展, 大模型各个领域的应用正在不断扩大. 本文尽力梳理各种材料, 将从概念定义, 类型分类, 训练以及应用等方面对大模型进行一个简要的概述.")]),t._v(" "),a("p",[t._v("如果你想了解大模型但是却缺乏基础的知识或者觉得无从下手, 那么阅读该文章可能对你有所帮助.")]),t._v(" "),a("p",[a("br"),a("br")]),t._v(" "),a("div",{staticClass:"center-container"},[a("img",{attrs:{src:"/screen_shot/openai-lockup.png",width:"50%"}})]),t._v(" "),a("h2",{attrs:{id:"_1-概念定义"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-概念定义"}},[t._v("#")]),t._v(" 1. 概念定义")]),t._v(" "),a("h3",{attrs:{id:"_1-1-人工智能主要概念"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-人工智能主要概念"}},[t._v("#")]),t._v(" 1.1 人工智能主要概念")]),t._v(" "),a("h4",{attrs:{id:"_1-1-1-应用领域"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-1-应用领域"}},[t._v("#")]),t._v(" 1.1.1 应用领域")]),t._v(" "),a("p",[a("img",{attrs:{src:"/screen_shot/image-20230822103452066.png",alt:"image-20230822103452066"}})]),t._v(" "),a("div",{staticClass:"center-container"},[a("p",[t._v("图1.1")])]),a("h4",{attrs:{id:"_1-1-2-算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-2-算法"}},[t._v("#")]),t._v(" 1.1.2 算法")]),t._v(" "),a("p",[a("img",{attrs:{src:"/screen_shot/image-20230822104120797.png",alt:"image-20230822104120797"}})]),t._v(" "),a("div",{staticClass:"center-container"},[a("p",[t._v("图1.2 Relationship among deep reinforcement learning, deep learning, reinforcement learning, supervised learning, unsupervised learning, machine learning, and, artificial intelligence. Deep learning and deep reinforcement learning are addressing many classical AI problems "),a("sup",{staticClass:"footnote-ref"},[a("a",{attrs:{href:"#footnote1"}},[t._v("[1]")]),a("a",{staticClass:"footnote-anchor",attrs:{id:"footnote-ref1"}})])])]),a("p",[t._v("机器学习(Machine Learning, ML): 机器学习是AI的一个核心子领域, 它让机器可以通过数据来学习和预测.")]),t._v(" "),a("ol",[a("li",[t._v("监督学习: 学习带标签的数据, 并预测未见数据的标签.\n"),a("ol",[a("li",[t._v("线性回归(Linear Regression)")]),t._v(" "),a("li",[t._v("支持向量机(Support Vector Machines)")]),t._v(" "),a("li",[t._v("决策树(Decision Trees)")]),t._v(" "),a("li",[t._v("随机森林(Random Forest)")])])]),t._v(" "),a("li",[t._v("无监督学习: 处理不带标签的数据, 常用于聚类和降维.\n"),a("ol",[a("li",[t._v("K均值(K-Means)")]),t._v(" "),a("li",[t._v("层次聚类(Hierarchical Clustering)")]),t._v(" "),a("li",[t._v("主成分分析(PCA)")])])]),t._v(" "),a("li",[t._v("强化学习: 智能体通过与环境互动并接收奖励或惩罚来学习\n"),a("ol",[a("li",[t._v("Q-learning")]),t._v(" "),a("li",[t._v("Deep Q Networks(DQN)")]),t._v(" "),a("li",[t._v("Actor-Critic 方法")]),t._v(" "),a("li",[t._v("Proximal Policy Optimization(PPO)")])])]),t._v(" "),a("li",[t._v("深度学习: 主要使用神经网络, 尤其是深层网络.\n"),a("ol",[a("li",[t._v("卷积神经网络(CNN)")]),t._v(" "),a("li",[t._v("循环神经网络(RNN)")]),t._v(" "),a("li",[t._v("长短时记忆网络(LSTM)")]),t._v(" "),a("li",[t._v("Transformer 结构, 如BERT, GPT等")])])])]),t._v(" "),a("h3",{attrs:{id:"_2-大模型的定义"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-大模型的定义"}},[t._v("#")]),t._v(" 2. 大模型的定义")]),t._v(" "),a("p",[t._v('"大模型"这个概念比较难定义, 到目前为止没有广泛接受的, 官方的定义. 其对应的英文单词为: '),a("strong",[t._v('"foundation model"')]),t._v(", 又时也称为: "),a("strong",[t._v('"general-purpose AI"')]),t._v(" 或 "),a("strong",[t._v('"GPAI"')]),t._v(". 指可以执行一系列的常规任务, 例如文本合成, 图像处理以及音频合成等的模型.")]),t._v(" "),a("p",[t._v("以下是一些定义:")]),t._v(" "),a("ol",[a("li",[a("p",[a("a",{attrs:{href:"https://arxiv.org/abs/2108.07258",target:"_blank",rel:"noopener noreferrer"}},[t._v("On the Opportunities and Risks of Foundation Models(2021)"),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("2021年8月份, 斯坦福大学教授李飞飞和100多位学者联名发表一份200多页的研究报告《On the Opportunities and Risk of Foundation Models》, 深度地综述了当前大规模预训练模型面临的机遇和挑战.")]),t._v(" "),a("blockquote",[a("p",[t._v("AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character.")]),t._v(" "),a("p",[t._v("随着模型(例如BERT, DALL-E, GPT-3)的兴起, 人工智能正在经历范式转变, 这些模型在大规模上对广泛的数据进行训练, 并适应广泛的下游任务. 我们称这些模型为基础模型, 以强调其关键的核心但不完整的特征.")])])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://blogs.nvidia.com/blog/2023/03/13/what-are-foundation-models",target:"_blank",rel:"noopener noreferrer"}},[t._v("Nvidia: What Are Foundation Models?"),a("OutboundLink")],1)]),t._v(" "),a("blockquote",[a("p",[t._v("Foundation models are AI neural networks trained on massive unlabeled datasets to handle a wide variety of jobs from translating text to analyzing medical images.")]),t._v(" "),a("p",[t._v("基础模型是在大量未标记数据集上训练的 AI 神经网络, 用于处理从翻译文本到分析医学图像的各种工作.")])])]),t._v(" "),a("li",[a("p",[t._v("大模型的5个关键特征")]),t._v(" "),a("ol",[a("li",[t._v("预训练: 使用大数据和大规模计算, 以便无需任何额外训练即可使用")]),t._v(" "),a("li",[t._v("通用: 一个模型可以用于许多任务")]),t._v(" "),a("li",[t._v("适应性强: 使用叙述文本作为模型输入")]),t._v(" "),a("li",[t._v("大: 例如GPT-3 有1750亿个参数. 但是随着参数的不断增长, 这个标准也在不断提高.")]),t._v(" "),a("li",[t._v("自我监督: 无提供特定标签")])])])]),t._v(" "),a("h3",{attrs:{id:"_3-大模型的类型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-大模型的类型"}},[t._v("#")]),t._v(" 3. 大模型的类型")]),t._v(" "),a("p",[a("img",{attrs:{src:"/screen_shot/image-20230822120030873.png",alt:"image-20230822120030873"}})]),t._v(" "),a("p",[t._v("大模型大致可分为三种类型: 语言模型、计算机视觉模型和生成模型."),a("sup",{staticClass:"footnote-ref"},[a("a",{attrs:{href:"#footnote2"}},[t._v("[2]")]),a("a",{staticClass:"footnote-anchor",attrs:{id:"footnote-ref2"}})])]),t._v(" "),a("h4",{attrs:{id:"_3-1-语言模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-语言模型"}},[t._v("#")]),t._v(" 3.1 语言模型")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("BERT")]),t._v(" "),a("p",[t._v("由Google开发的BERT是一种预先训练的语言模型, 能够理解自然语言文本的细微差别. 根据谷歌的说法, BERT在各种自然语言处理任务(包括问答, 翻译, 情感分析和预测文本)上优于以前基于递归神经网络(RNN)的语言模型")])]),t._v(" "),a("li",[a("p",[t._v("GPT3")]),t._v(" "),a("p",[t._v("由OpenAI开发的GPT-3是一个更大的语言模型, 已经在一个非常大的数据集上进行了训练. GPT-3 拥有 1750 亿个参数, 可以生成与人类编写的文本无法区分的文本. 该模型已用于各种应用, 包括聊天机器人和虚拟助手.")])]),t._v(" "),a("li",[a("p",[t._v("T5")]),t._v(" "),a("p",[t._v("T5是Google开发的最新语言模型, 它采用不同的自然语言处理方法. T5 不是针对 BERT 等特定任务进行微调, 而是一种通用语言模型, 经过训练以执行广泛的任务, 包括文本分类、问答和摘要等. T5 使用统一的文本到文本格式, 这使其能够轻松适应各种自然语言处理任务.")])])]),t._v(" "),a("h4",{attrs:{id:"_3-2-视觉模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-视觉模型"}},[t._v("#")]),t._v(" 3.2 视觉模型")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("ResNet")]),t._v(" "),a("p",[t._v("由Microsoft开发的ResNet是一个深度神经网络, 能够以极高的精度对图像进行分类. 该模型已用于各种应用, 包括自动驾驶汽车的图像识别")])]),t._v(" "),a("li",[a("p",[t._v("EfficientNet")]),t._v(" "),a("p",[t._v("由Google开发的EfficientNet是另一种计算机视觉模型, 在各种图像分类任务上取得了最先进的结果. 该模型以其效率而著称, 与其他领先的计算机视觉模型相比, 所需的参数要少得多.")])]),t._v(" "),a("li",[a("p",[t._v("YOLO (You Only Look Once)")]),t._v(" "),a("p",[t._v("YOLO是一种实时物体检测系统, 能够以非常高的精度检测图像中的物体. 该模型已用于各种应用, 包括自动驾驶汽车和安全系统.")])])]),t._v(" "),a("h4",{attrs:{id:"_3-3-生成模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-生成模型"}},[t._v("#")]),t._v(" 3.3 生成模型")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("DALL-E")]),t._v(" "),a("p",[t._v("由OpenAI开发的DALL-E是一种生成模型, 能够从自然语言提示创建图像. 该模型引起了艺术界的极大兴趣, 因为它能够生成高度逼真和富有想象力的图像.")])]),t._v(" "),a("li",[a("p",[t._v("GANs")]),t._v(" "),a("p",[t._v("由Ian Goodfellow开发的GAN(生成对抗网络)是一种生成模型, 能够通过使两个神经网络相互对抗来生成新数据. 谷歌的BigGAN就是这种模型的一个例子, 它在一个巨大的图像数据集上进行了训练, 使其能够创造出具有令人难以置信的细节和真实感的生成艺术. BigGAN 已广泛用于广告、营销, 甚至用于生成虚拟视频游戏环境.")])]),t._v(" "),a("li",[a("p",[t._v("VAEs")]),t._v(" "),a("p",[t._v("VAEs 是一种生成模型, 能够通过学习数据集的底层结构来生成新数据. 这些模型已用于降维和异常检测等应用.")])])]),t._v(" "),a("h2",{attrs:{id:"_2-关于训练"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-关于训练"}},[t._v("#")]),t._v(" 2. 关于训练 "),a("sup",{staticClass:"footnote-ref"},[a("a",{attrs:{href:"#footnote3"}},[t._v("[3]")]),a("a",{staticClass:"footnote-anchor",attrs:{id:"footnote-ref3"}})])]),t._v(" "),a("h3",{attrs:{id:"_2-1-通用步骤"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-通用步骤"}},[t._v("#")]),t._v(" 2.1 通用步骤")]),t._v(" "),a("ol",[a("li",[a("p",[a("em",[a("strong",[t._v("收集数据集")])])]),t._v(" "),a("p",[t._v("基础模型需要在非常大的数据集(例如文本或代码)上进行训练. 数据集应尽可能多样化, 并且应涵盖您希望模型能够执行的任务.")])]),t._v(" "),a("li",[a("p",[a("em",[a("strong",[t._v("准备数据集")])])]),t._v(" "),a("p",[t._v("需要先准备数据集, 然后才能用于训练模型. 这包括清理数据、删除任何错误以及以模型可以理解的方式设置数据的格式.")])]),t._v(" "),a("li",[a("p",[a("em",[a("strong",[t._v("打标记")])])]),t._v(" "),a("p",[t._v("标记化是将文本分解为单个标记的过程. 这对于基础模型是必需的, 因为它们需要能够理解文本中的各个单词和短语.")])]),t._v(" "),a("li",[a("p",[a("em",[a("strong",[t._v("配置训练过程")])])]),t._v(" "),a("p",[t._v("配置训练过程以指定超参数、训练算法体系结构和将使用的计算资源.")])]),t._v(" "),a("li",[a("p",[a("em",[a("strong",[t._v("训练模型")])])]),t._v(" "),a("p",[t._v("将使用指定的训练模型体系结构在数据集上训练模型. 这可能需要很长时间, 具体取决于模型的大小和数据量.")])]),t._v(" "),a("li",[a("p",[a("em",[a("strong",[t._v("评估模型")])])]),t._v(" "),a("p",[t._v("训练模型后, 您需要在保留数据集上评估其性能. 这将帮助您确定模型是否按预期执行.")])]),t._v(" "),a("li",[a("p",[a("em",[a("strong",[t._v("部署模型")])])]),t._v(" "),a("p",[t._v("对模型的性能感到满意后, 可以将其部署到生产环境. 这意味着使模型可供用户使用, 以便他们可以使用它来执行任务.")])])]),t._v(" "),a("details",{staticClass:"custom-block details"},[a("summary",[t._v("什么是迭代?")]),t._v(" "),a("p",[t._v("一次迭代一般包含以下三个步骤:")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("向前传播(forward)\n简单理解就是将上一层的输出作为下一层的输入, 并计算下一层的输出, 一直到运算到输出层为止.\n"),a("img",{attrs:{src:"/screen_shot/image-20230822154444121.png",alt:"image-20230822154444121"}})]),t._v(" "),a("p",[t._v("用矩阵来表示:\n"),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("msup",[a("mi",[t._v("z")]),a("mrow",[a("mo",{attrs:{stretchy:"false"}},[t._v("(")]),a("mi",[t._v("l")]),a("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1)],1),a("mo",[t._v("=")]),a("msup",[a("mi",[t._v("W")]),a("mrow",[a("mo",{attrs:{stretchy:"false"}},[t._v("(")]),a("mi",[t._v("l")]),a("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1)],1),a("msup",[a("mi",[t._v("a")]),a("mrow",[a("mo",{attrs:{stretchy:"false"}},[t._v("(")]),a("mi",[t._v("l")]),a("mo",[t._v("−")]),a("mn",[t._v("1")]),a("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1)],1),a("mo",[t._v("+")]),a("msup",[a("mi",[t._v("b")]),a("mrow",[a("mo",{attrs:{stretchy:"false"}},[t._v("(")]),a("mi",[t._v("l")]),a("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("z^{(l)} = W^{(l)}a^{(l-1)}+b^{(l)}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.888em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.04398em"}},[t._v("z")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.888em"}},[a("span",{staticStyle:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mopen mtight"},[t._v("(")]),a("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")]),a("span",{staticClass:"mclose mtight"},[t._v(")")])])])])])])])])]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}}),a("span",{staticClass:"mrel"},[t._v("=")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.9713em","vertical-align":"-0.0833em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.13889em"}},[t._v("W")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.888em"}},[a("span",{staticStyle:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mopen mtight"},[t._v("(")]),a("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")]),a("span",{staticClass:"mclose mtight"},[t._v(")")])])])])])])])])]),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathnormal"},[t._v("a")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.888em"}},[a("span",{staticStyle:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mopen mtight"},[t._v("(")]),a("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")]),a("span",{staticClass:"mbin mtight"},[t._v("−")]),a("span",{staticClass:"mord mtight"},[t._v("1")]),a("span",{staticClass:"mclose mtight"},[t._v(")")])])])])])])])])]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222em"}}),a("span",{staticClass:"mbin"},[t._v("+")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.888em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathnormal"},[t._v("b")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.888em"}},[a("span",{staticStyle:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mopen mtight"},[t._v("(")]),a("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")]),a("span",{staticClass:"mclose mtight"},[t._v(")")])])])])])])])])])])])]),t._v(" "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("msup",[a("mi",[t._v("a")]),a("mrow",[a("mo",{attrs:{stretchy:"false"}},[t._v("(")]),a("mi",[t._v("l")]),a("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1)],1),a("mo",[t._v("=")]),a("mi",[t._v("σ")]),a("mo",{attrs:{stretchy:"false"}},[t._v("(")]),a("msup",[a("mi",[t._v("z")]),a("mrow",[a("mo",{attrs:{stretchy:"false"}},[t._v("(")]),a("mi",[t._v("l")]),a("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1)],1),a("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("a^{(l)}=\\sigma(z^{(l)})")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.888em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathnormal"},[t._v("a")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.888em"}},[a("span",{staticStyle:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mopen mtight"},[t._v("(")]),a("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")]),a("span",{staticClass:"mclose mtight"},[t._v(")")])])])])])])])])]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}}),a("span",{staticClass:"mrel"},[t._v("=")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.138em","vertical-align":"-0.25em"}}),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.03588em"}},[t._v("σ")]),a("span",{staticClass:"mopen"},[t._v("(")]),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.04398em"}},[t._v("z")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.888em"}},[a("span",{staticStyle:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mopen mtight"},[t._v("(")]),a("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")]),a("span",{staticClass:"mclose mtight"},[t._v(")")])])])])])])])])]),a("span",{staticClass:"mclose"},[t._v(")")])])])]),t._v("\n其中"),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("σ")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\sigma")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.4306em"}}),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.03588em"}},[t._v("σ")])])])]),t._v("为激活函数, 如 Sigmoid, ReLU, PReLU等.")])]),t._v(" "),a("li",[a("p",[t._v("计算损失\n模型输出完成后, 接下来就是要评估模型的表现. 这是通过计算损失函数(Loss Function)来实现的. 损失函数量化了模型预测和真实标签之间的差距. 常见的损失函括交叉熵损失(用于分类问题)和均方误差(用于回归问题)\n损失函数的计算通常表示为:  "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("L")]),a("mi",[t._v("o")]),a("mi",[t._v("s")]),a("mi",[t._v("s")]),a("mo",[t._v("=")]),a("msub",[a("mi",[t._v("f")]),a("mrow",[a("mo",{attrs:{stretchy:"false"}},[t._v("(")]),a("mi",[t._v("M")]),a("mi",[t._v("o")]),a("mi",[t._v("d")]),a("mi",[t._v("e")]),a("mi",[t._v("l")]),a("mi",[t._v("O")]),a("mi",[t._v("u")]),a("mi",[t._v("t")]),a("mi",[t._v("p")]),a("mi",[t._v("u")]),a("mi",[t._v("t")]),a("mo",{attrs:{separator:"true"}},[t._v(",")]),a("mi",[t._v("T")]),a("mi",[t._v("r")]),a("mi",[t._v("u")]),a("mi",[t._v("e")]),a("mi",[t._v("L")]),a("mi",[t._v("a")]),a("mi",[t._v("b")]),a("mi",[t._v("e")]),a("mi",[t._v("l")]),a("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("Loss=f_{(Model Output,True Label)}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.6833em"}}),a("span",{staticClass:"mord mathnormal"},[t._v("L")]),a("span",{staticClass:"mord mathnormal"},[t._v("oss")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}}),a("span",{staticClass:"mrel"},[t._v("=")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.0496em","vertical-align":"-0.3552em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.10764em"}},[t._v("f")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.3448em"}},[a("span",{staticStyle:{top:"-2.5198em","margin-left":"-0.1076em","margin-right":"0.05em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mopen mtight"},[t._v("(")]),a("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.10903em"}},[t._v("M")]),a("span",{staticClass:"mord mathnormal mtight"},[t._v("o")]),a("span",{staticClass:"mord mathnormal mtight"},[t._v("d")]),a("span",{staticClass:"mord mathnormal mtight"},[t._v("e")]),a("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.02778em"}},[t._v("lO")]),a("span",{staticClass:"mord mathnormal mtight"},[t._v("u")]),a("span",{staticClass:"mord mathnormal mtight"},[t._v("tp")]),a("span",{staticClass:"mord mathnormal mtight"},[t._v("u")]),a("span",{staticClass:"mord mathnormal mtight"},[t._v("t")]),a("span",{staticClass:"mpunct mtight"},[t._v(",")]),a("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.13889em"}},[t._v("T")]),a("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.02778em"}},[t._v("r")]),a("span",{staticClass:"mord mathnormal mtight"},[t._v("u")]),a("span",{staticClass:"mord mathnormal mtight"},[t._v("e")]),a("span",{staticClass:"mord mathnormal mtight"},[t._v("L")]),a("span",{staticClass:"mord mathnormal mtight"},[t._v("ab")]),a("span",{staticClass:"mord mathnormal mtight"},[t._v("e")]),a("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")]),a("span",{staticClass:"mclose mtight"},[t._v(")")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.3552em"}},[a("span")])])])])])])])])])]),t._v(" "),a("li",[a("p",[t._v("反向传播(backward)\n计算出损失之后, 接下来的任务是更新模型的参数以便减少这个损失. 反向传播是一种高效计算损失函数关于每个参数梯度的方法.")]),t._v(" "),a("ol",[a("li",[t._v("计算梯度: 从输出层开始, 计算损失函数关于各层参数的偏导数(梯度)")]),t._v(" "),a("li",[t._v("更新参数: 用这些计算出的梯度来更新模型参数. 参数的更新通常使用优化算法(如梯度下降)  "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("N")]),a("mi",[t._v("e")]),a("mi",[t._v("w")]),a("mi",[t._v("P")]),a("mi",[t._v("a")]),a("mi",[t._v("r")]),a("mi",[t._v("a")]),a("mi",[t._v("m")]),a("mi",[t._v("e")]),a("mi",[t._v("t")]),a("mi",[t._v("e")]),a("mi",[t._v("r")]),a("mo",[t._v("=")]),a("mi",[t._v("O")]),a("mi",[t._v("l")]),a("mi",[t._v("d")]),a("mi",[t._v("P")]),a("mi",[t._v("a")]),a("mi",[t._v("r")]),a("mi",[t._v("a")]),a("mi",[t._v("m")]),a("mi",[t._v("e")]),a("mi",[t._v("t")]),a("mi",[t._v("e")]),a("mi",[t._v("r")]),a("mo",[t._v("−")]),a("mi",[t._v("α")]),a("mo",[t._v("×")]),a("mi",[t._v("G")]),a("mi",[t._v("r")]),a("mi",[t._v("a")]),a("mi",[t._v("d")]),a("mi",[t._v("i")]),a("mi",[t._v("e")]),a("mi",[t._v("n")]),a("mi",[t._v("t")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("New Parameter= Old Parameter−\\alpha \\times Gradient")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.6833em"}}),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.10903em"}},[t._v("N")]),a("span",{staticClass:"mord mathnormal"},[t._v("e")]),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.13889em"}},[t._v("wP")]),a("span",{staticClass:"mord mathnormal"},[t._v("a")]),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.02778em"}},[t._v("r")]),a("span",{staticClass:"mord mathnormal"},[t._v("am")]),a("span",{staticClass:"mord mathnormal"},[t._v("e")]),a("span",{staticClass:"mord mathnormal"},[t._v("t")]),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.02778em"}},[t._v("er")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}}),a("span",{staticClass:"mrel"},[t._v("=")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.7778em","vertical-align":"-0.0833em"}}),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.01968em"}},[t._v("Ol")]),a("span",{staticClass:"mord mathnormal"},[t._v("d")]),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.13889em"}},[t._v("P")]),a("span",{staticClass:"mord mathnormal"},[t._v("a")]),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.02778em"}},[t._v("r")]),a("span",{staticClass:"mord mathnormal"},[t._v("am")]),a("span",{staticClass:"mord mathnormal"},[t._v("e")]),a("span",{staticClass:"mord mathnormal"},[t._v("t")]),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.02778em"}},[t._v("er")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222em"}}),a("span",{staticClass:"mbin"},[t._v("−")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.6667em","vertical-align":"-0.0833em"}}),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.0037em"}},[t._v("α")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222em"}}),a("span",{staticClass:"mbin"},[t._v("×")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.6944em"}}),a("span",{staticClass:"mord mathnormal"},[t._v("G")]),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.02778em"}},[t._v("r")]),a("span",{staticClass:"mord mathnormal"},[t._v("a")]),a("span",{staticClass:"mord mathnormal"},[t._v("d")]),a("span",{staticClass:"mord mathnormal"},[t._v("i")]),a("span",{staticClass:"mord mathnormal"},[t._v("e")]),a("span",{staticClass:"mord mathnormal"},[t._v("n")]),a("span",{staticClass:"mord mathnormal"},[t._v("t")])])])])])])])])]),t._v(" "),a("h3",{attrs:{id:"_2-2-训练算法的目标"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-训练算法的目标"}},[t._v("#")]),t._v(" 2.2 训练算法的目标 "),a("sup",{staticClass:"footnote-ref"},[a("a",{attrs:{href:"#footnote4"}},[t._v("[4]")]),a("a",{staticClass:"footnote-anchor",attrs:{id:"footnote-ref4"}})])]),t._v(" "),a("h4",{attrs:{id:"利用海量的数据-leveraging-broad-data"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#利用海量的数据-leveraging-broad-data"}},[t._v("#")]),t._v(" 利用海量的数据(Leveraging broad data)")]),t._v(" "),a("p",[t._v("当前网络上产生的海量数据, 以多种形式出现. 包括文本, 图像, 录音, 视频和机器人传感器. 由于这些数据缺乏额外的标注, 所以当前研究都集中在设计自我监督的算法, 利用每种类型的独特结构的数据产生基础模型的训练信号.")]),t._v(" "),a("h4",{attrs:{id:"领域完备性-domain-completeness"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#领域完备性-domain-completeness"}},[t._v("#")]),t._v(" 领域完备性(Domain completeness)")]),t._v(" "),a("p",[t._v("大模型需要解决的一个重要目标就是需要对领域中的下游任务具有广泛而有用的能力. 这个属性对于大模型的通用性至关重要. 但是哪些任务会影响领域完备性并不是显而易见的, 甚至如何去评估一个模型的广泛性也是困难的.")]),t._v(" "),a("h4",{attrs:{id:"扩展和计算效率-scaling-and-compute-efficiency"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#扩展和计算效率-scaling-and-compute-efficiency"}},[t._v("#")]),t._v(" 扩展和计算效率(Scaling and compute efficiency)")]),t._v(" "),a("p",[t._v("自我监督的算法的兴起是的模型的大小和计算资源瓶颈日益凸显. 训练的效率在不同的设计上可能会大有不同, 因此, 训练研究人员的一个主要目标是设计具有更丰富的训练信号的训练目标, 从而使模型学习更快, 获得更强的能力.")]),t._v(" "),a("h3",{attrs:{id:"_2-3-重要的设计选择"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-重要的设计选择"}},[t._v("#")]),t._v(" 2.3 重要的设计选择")]),t._v(" "),a("h4",{attrs:{id:"抽象的级别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#抽象的级别"}},[t._v("#")]),t._v(" 抽象的级别")]),t._v(" "),a("p",[t._v("一个基本问题是基础模型的输入表示应该是什么.")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("一种选择是在"),a("strong",[t._v("原始字节级别")]),t._v("对输入进行建模. 但是, 这种高维数可能会导致模型专注于预测输入的语义较少的方面, 从而减慢其获得更普遍有用的功能的速度. 并且在Transformer中其计算成本随输入大小呈二次增长.")])]),t._v(" "),a("li",[a("p",[t._v("另一种选择是"),a("strong",[t._v("使用领域知识")]),t._v('来减少模型的输入空间——此类策略包括"块向量表示"(patch embedding) 以及固定或学习的标记化 . 这些方法可能会减轻生成方法面临的一些挑战, 但代价是它们可能会抛弃输入中可能有用的信息.')])])]),t._v(" "),a("h4",{attrs:{id:"生成模型与判别模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#生成模型与判别模型"}},[t._v("#")]),t._v(" 生成模型与判别模型")]),t._v(" "),a("ol",[a("li",[a("p",[a("em",[a("strong",[t._v("生成模型")])]),t._v("\n试图学习数据的联合概率分布 "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("P")]),a("mo",{attrs:{stretchy:"false"}},[t._v("(")]),a("mi",[t._v("X")]),a("mo",{attrs:{separator:"true"}},[t._v(",")]),a("mi",[t._v("Y")]),a("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("P(X, Y)")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1em","vertical-align":"-0.25em"}}),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.13889em"}},[t._v("P")]),a("span",{staticClass:"mopen"},[t._v("(")]),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.07847em"}},[t._v("X")]),a("span",{staticClass:"mpunct"},[t._v(",")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.1667em"}}),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.22222em"}},[t._v("Y")]),a("span",{staticClass:"mclose"},[t._v(")")])])])]),t._v(", 其中 "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("X")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("X")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.6833em"}}),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.07847em"}},[t._v("X")])])])]),t._v(" 是输入特征, "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("Y")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("Y")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.6833em"}}),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.22222em"}},[t._v("Y")])])])]),t._v("是标签. (GMM, Naive Bayes, HMM, GANs)")]),t._v(" "),a("ol",[a("li",[t._v("自回归基础模型: 在生成序列(如文本或音乐)时, 每一个元素都是基于前面所有已生成元素的函数")]),t._v(" "),a("li",[t._v('去噪基础模型:  这类模型通常会先接收一个被添加噪声或以某种方式损坏的输入, 然后尝试重构或生成一个"干净"的版本.')])])])]),t._v(" "),a("p",[t._v("虽然生成训练方法有其优点, 但一些判别方法也最近开始受到关注.")]),t._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[t._v("***判别模型***试图学习条件概率分布"),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("P")]),a("mo",{attrs:{stretchy:"false"}},[t._v("(")]),a("mi",[t._v("Y")]),a("mi",{attrs:{mathvariant:"normal"}},[t._v("∣")]),a("mi",[t._v("X")]),a("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("P(Y|X)")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1em","vertical-align":"-0.25em"}}),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.13889em"}},[t._v("P")]),a("span",{staticClass:"mopen"},[t._v("(")]),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.22222em"}},[t._v("Y")]),a("span",{staticClass:"mord"},[t._v("∣")]),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.07847em"}},[t._v("X")]),a("span",{staticClass:"mclose"},[t._v(")")])])])]),t._v(", 即在给定输入"),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("X")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("X")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.6833em"}}),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.07847em"}},[t._v("X")])])])]),t._v("的情况下, 输出"),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mi",[t._v("Y")])],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("Y")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.6833em"}}),a("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.22222em"}},[t._v("Y")])])])]),t._v("的概率.(逻辑回归, 支持向量机SVM, 决策树, 随机森林, CNN)")])]),t._v(" "),a("p",[t._v("通常在分类任务中表现更好, 计算效率更高. 但是对数据要求量更大, 数据稀少时不如生成模型表现好.")]),t._v(" "),a("p",[t._v("更好地理解生成和判别训练之间的权衡, 以及捕获两种方法的最佳之处, 仍然是未来研究的有趣方向.")]),t._v(" "),a("h4",{attrs:{id:"捕获多模态关系"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#捕获多模态关系"}},[t._v("#")]),t._v(" 捕获多模态关系")]),t._v(" "),a("p",[t._v("另一个日益重要的研究领域是捕获多种类型数据之间的关系. 这意味着根据情境和模型设计者的目标, 具体内容可能有所不同. 例如, CLIP [Radford et al. 2021] 和 ViLBERT [Lu et al. 2019a] 都是多模态视觉-语言模型, 但在多模态的具体实现方式上有所不同. 前者将图像和文本分别编码为向量, 使得只有单一模态样本的用户也能检索、评分或分类来自另一模态的样本. 后者则在模型的早期阶段就开始联合处理图像和文本, 这有助于支持诸如视觉问题回答这样的下游应用, 在这些应用中, 需要对一对相关的图像和文本(例如, 图像及其相关问题)进行推理. 多模态基础模型仍然是一个崭新的研究领域;关于模型可以以何种不同方式实现多模态, 以及这些额外的模态能带来哪些能力, 还有很多未探索的问题.")]),t._v(" "),a("p",[a("strong",[t._v("挑战")])]),t._v(" "),a("ol",[a("li",[t._v("数据不平衡: 不同模态的数据量和质量可能有很大的差异.")]),t._v(" "),a("li",[t._v("复杂性: 多模态信息通常意味着更高的计算和模型复杂性.")]),t._v(" "),a("li",[t._v("语义鸿沟: 不同模态之间可能存在语义鸿沟, 使得捕获它们之间的内在关联变得困难.")])]),t._v(" "),a("h3",{attrs:{id:"_2-4-未来的方向"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-未来的方向"}},[t._v("#")]),t._v(" 2.4 未来的方向 "),a("sup",{staticClass:"footnote-ref"},[a("a",{attrs:{href:"#footnote4"}},[t._v("[4:1]")]),a("a",{staticClass:"footnote-anchor",attrs:{id:"footnote-ref4:1"}})])]),t._v(" "),a("h4",{attrs:{id:"解决特异性"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#解决特异性"}},[t._v("#")]),t._v(" 解决特异性")]),t._v(" "),a("p",[t._v("目前在自然语言处理, 计算机视觉和语音处理中盛行不同的方法. 这有两个主要缺点: 首先, 这些不同的技术使得掌握这些方法中每种方法的共同线索和科学原理变得具有挑战性. 其次, 这种领域特异性要求为每个新领域从头开始开发新的基础模型训练方法, 包括医学、科学和新的多模态设置.")]),t._v(" "),a("h4",{attrs:{id:"获得丰富的训练信号"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#获得丰富的训练信号"}},[t._v("#")]),t._v(" 获得丰富的训练信号")]),t._v(" "),a("p",[t._v("很明显, 并非所有训练目标都是平等的——有些训练目标比其他目标效率更高, 从而转化为给定计算预算下功能更强大的基础模型. 是否有比目前已知的训练方法更有效的训练方法？如果是这样, 我们如何找到它们？")]),t._v(" "),a("h4",{attrs:{id:"基础模型的目标导向训练"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基础模型的目标导向训练"}},[t._v("#")]),t._v(" 基础模型的目标导向训练")]),t._v(" "),a("p",[t._v("我们能否训练基础模型, 其中理解和可靠地执行复杂世界中目标的能力是模型训练目标的一部分？专注于开发一般能力将这个方向与通过强化学习使现有基础模型适应特定任务的目标区分开来")]),t._v(" "),a("h2",{attrs:{id:"_3-行业应用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-行业应用"}},[t._v("#")]),t._v(" 3. 行业应用 "),a("sup",{staticClass:"footnote-ref"},[a("a",{attrs:{href:"#footnote4"}},[t._v("[4:2]")]),a("a",{staticClass:"footnote-anchor",attrs:{id:"footnote-ref4:2"}})])]),t._v(" "),a("h3",{attrs:{id:"_3-1-医疗和生物医学"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-医疗和生物医学"}},[t._v("#")]),t._v(" 3.1 医疗和生物医学")]),t._v(" "),a("h4",{attrs:{id:"医疗保障的机会"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#医疗保障的机会"}},[t._v("#")]),t._v(" 医疗保障的机会")]),t._v(" "),a("h5",{attrs:{id:"对医院"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#对医院"}},[t._v("#")]),t._v(" 对医院:")]),t._v(" "),a("ol",[a("li",[t._v("可以改善医院提供护理的效率和准确率. 如用于诊断/治疗的自动辅助系统、患者记录摘要和患者问题的回答.[Davenport and Kalakota 2019; Nie et al. 2018; Wang et al. 2021b]")]),t._v(" "),a("li",[t._v("特别是在 COVID-19 等紧急大流行危机中, 快速诊断/筛查(例如, 胸部 X 射线图像的自动分析)以及患者和公众的自动问答(例如, 症状检查和护理)和公众(例如, 疾病预防)对于减少疾病传播和为危重患者分配医疗保健资源、挽救更多生命至关重要 [Lalmuanawma et al. 2020].")]),t._v(" "),a("li",[t._v("基础模型可以提高提供者护理的效率和准确性. 医疗保健提供者花费不必要的时间来编辑电子健康记录 (EHR) [Kocher 2021]")]),t._v(" "),a("li",[t._v("可预防的医疗错误(例如, 再入院、手术错误)会导致医疗保健浪费 [Shrank 等人, 2019 年;沙阿等人, 2020 年]")])]),t._v(" "),a("h5",{attrs:{id:"对患者"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#对患者"}},[t._v("#")]),t._v(" 对患者:")]),t._v(" "),a("ol",[a("li",[t._v("大模型可提供门诊预约和相关信息. [Bates 2019]")]),t._v(" "),a("li",[t._v("回答患者相关问题.[Demner-Fushman et al. 2020]")]),t._v(" "),a("li",[t._v("药物的相关解答(文本, 图片等多模态) [Chaix et al. 2019]")]),t._v(" "),a("li",[t._v("对大型流行病等医疗问题的问答系统(特别是COVID-19) [Bharti et al. 2020; Herriman et al. 2020]")])]),t._v(" "),a("h4",{attrs:{id:"生物医学的机会"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#生物医学的机会"}},[t._v("#")]),t._v(" 生物医学的机会")]),t._v(" "),a("ol",[a("li",[t._v("基础模型可以促进生物医学研究, 例如药物的发现和对疾病的理解, 最终转化为改进的医疗保健解决方案[Hanney等人, 2015]")]),t._v(" "),a("li",[t._v("基础模型具有强大的生成能力(例如, GPT-3 中的连贯文本生成), 这可以帮助生物医学研究中的生成任务, 例如生成实验方案(临床试验)和根据现有数据设计有效的分子(药物发现)[Kadurin 等人, 2017 年;哈勒等人, 2019 年]")]),t._v(" "),a("li",[t._v("基础模型有可能整合医学中的各种数据模式, 从而能够从多个尺度(使用分子、患者和人口水平的数据)和多个知识来源(使用成像、文本和化学描述)研究生物医学概念(例如疾病).  这促进了生物医学发现, 如果使用单一模态数据很难获得[Lanckriet等人, 2004年;Aerts 等人, 2006 年;孔等人, 2011;里贝罗等人, 2012年;王等. 2014,  2015c;鲁伊斯等人, 2020 年;吴等人, 2021h]")]),t._v(" "),a("li",[t._v("基础模型还支持跨模式的知识转移. Lu 等人 [2021a] 展示了如何在自然语言(一种数据丰富的模态)上训练的变压器模型如何适应其他基于序列的任务, 例如蛋白质折叠预测, 这是生物医学中一项长期研究的预测任务 [Jumper 等人, 2020]")])]),t._v(" "),a("h4",{attrs:{id:"挑战与风险"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#挑战与风险"}},[t._v("#")]),t._v(" 挑战与风险")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("多模态.")]),t._v(" "),a("p",[t._v("医学数据是高度多模态的, 具有各种数据类型(文本、图像、视频、数据库、分子)、规模(分子、基因、细胞、组织、患者、人口)和风格(专业和非专业语言). 当前的自我监督模型是针对每种模式开发的(例如, 文本 、图像 、基因、蛋白质 ), 并且不会共同学习不同的模式. 为了从这些不同的多模态医学数据中学习跨模态和跨模态信息, 我们需要研究基础模型训练中的特征级和语义级融合策略. 如果做得有效, 这有可能统一生物医学知识并促进发现")])]),t._v(" "),a("li",[a("p",[t._v("可解释性.")]),t._v(" "),a("p",[t._v("可解释性——为决策提供证据和逻辑步骤——在医疗保健和生物医学中至关重要, 并且根据《通用数据保护条例》(GDPR) 是强制性的. 例如, 在诊断和临床试验中, 必须将患者的症状和时间相关性解释为证据. 这有助于解决系统与人类专家之间潜在的分歧. 医疗保健中的知情同意也需要可解释性. 然而, 当前基础模型的训练目标不包括可解释性, 需要未来朝这个方向进行研究. 合并知识图谱可能是进一步提高模型可解释性的一步")])]),t._v(" "),a("li",[a("p",[t._v("法律和道德法规.")])]),t._v(" "),a("li",[a("p",[t._v("外推法.")]),t._v(" "),a("p",[t._v("生物医学发现的过程涉及外推. 例如, 基础模型必须能够快速适应新的实验技术(例如, 新的测定方法, 新的成像技术, 例如高分辨率显微镜)或新的设置(例如, 新的目标疾病, 例如COVID-19). 利用现有数据集并推断到新设置的能力是生物医学中机器学习的一个关键挑战. 虽然 GPT-3 表现出一些外推行为(例如, 生成以前从未见过的新文本), 但其机制尚不清楚, 仍处于起步阶段. 需要进一步的研究来提高基础模型的外推能力, 特别是在考虑医疗保健和生物医学固有的各种数据模式和任务时, 但在当前的 GPT-3 和相关模型中通常不研究.")])])]),t._v(" "),a("h3",{attrs:{id:"_3-2-法律"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-法律"}},[t._v("#")]),t._v(" 3.2 法律")]),t._v(" "),a("h4",{attrs:{id:"机会"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#机会"}},[t._v("#")]),t._v(" 机会")]),t._v(" "),a("p",[a("img",{attrs:{src:"/screen_shot/image-20230828141351499.png",alt:"image-20230828141351499"}})]),t._v(" "),a("p",[a("strong",[t._v("大模型独一无二的优势")])]),t._v(" "),a("ol",[a("li",[a("p",[t._v("有限注释学习:")]),t._v(" "),a("p",[t._v("注释的成本数据非常高. 通常, 制作高质量标签的专业知识只能在律师身上找到, 他们每小时收费数百美元. 即使在获得标签之后, 某些数据也可能是错误的, 敏感的, 不能汇集在一起训练一个大的语言模型. 鉴于最近的进展在few-shot学习中[Brown et al. 2020], 基础模型是最有前途的路径之一用于具有有限注释的学习模型.")])]),t._v(" "),a("li",[a("p",[t._v("大量历史数据:")]),t._v(" "),a("p",[t._v("法律决策需要不同尺度的背景:所有历史知识判决和标准, 判例法的知识, 仍然适用于目前, 和了解手头个案的细微差别. 基础模型是有可能学习历史和法律背景的共同表征为个别情况建模的语言能力和精度.")])])]),t._v(" "),a("h4",{attrs:{id:"挑战与风险-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#挑战与风险-2"}},[t._v("#")]),t._v(" 挑战与风险")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("长文本的叙述.")]),t._v(" "),a("p",[t._v("通常美国法庭使用的陈述文件长度在4,700字到15,000字之间. 一个案件回溯文件通常达到20,000到30,000字. 目前大模型对于长文本的生成无法达到这个长度.")])]),t._v(" "),a("li",[a("p",[t._v("检索, 概念漂移, 论点形成和逻辑推理.")]),t._v(" "),a("p",[t._v("目前大模型对于论点的逻辑推理部分能力较弱.")])]),t._v(" "),a("li",[a("p",[t._v("准确度.")]),t._v(" "),a("p",[t._v("基础模型在这个过程中制造虚假事实, 这是一个已经存在的问题出现在当前的模型中[Gretz et al. 2020;Zellers et al. [2019b]. 特异性和真实性是两回事, 在法律环境中尤为重要, 不精确的陈述可能会导致激烈的、意想不到的后果和虚假陈述可能导致对律师的制裁.")])]),t._v(" "),a("li",[a("p",[t._v("适应性.")]),t._v(" "),a("p",[t._v("不同的法律任务可能需要不同的训练过程, 自适应目前较差.")])])]),t._v(" "),a("h3",{attrs:{id:"_3-3-教育"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-教育"}},[t._v("#")]),t._v(" 3.3 教育")]),t._v(" "),a("h4",{attrs:{id:"机会-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#机会-2"}},[t._v("#")]),t._v(" 机会")]),t._v(" "),a("p",[a("img",{attrs:{src:"/screen_shot/image-20230829114824982.png",alt:"image-20230829114824982"}})]),t._v(" "),a("h4",{attrs:{id:"挑战与风险-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#挑战与风险-3"}},[t._v("#")]),t._v(" 挑战与风险")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("判断学生的作业是否是由AI生成的.")]),t._v(" "),a("p",[t._v("VSCode推出了CoPilot, 这使得编程初学者的体检受到影响.")])]),t._v(" "),a("li",[a("p",[t._v("隐私和安全")]),t._v(" "),a("p",[t._v("在美国, 学生信息尤其是13岁一下的儿童尤其重要.FERPA限制了教师分享学生作业, 这可能直接影响用于培训和评估基础模型的数据的主动性. 包括基础模型的权重是否会以某种方式泄露数据.n [Nasr et al. 2018; Song et al. 2017]")])])]),t._v(" "),a("hr",{staticClass:"footnotes-sep"}),t._v(" "),a("section",{staticClass:"footnotes"},[a("ol",{staticClass:"footnotes-list"},[a("li",{staticClass:"footnote-item",attrs:{id:"footnote1"}},[a("p",[t._v("图来自"),a("a",{attrs:{href:"https://arxiv.org/pdf/1810.06339.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("DEEP REINFORCEMENT LEARNING"),a("OutboundLink")],1),t._v("中的Figure2 "),a("a",{staticClass:"footnote-backref",attrs:{href:"#footnote-ref1"}},[t._v("↩︎")])])]),t._v(" "),a("li",{staticClass:"footnote-item",attrs:{id:"footnote2"}},[a("p",[a("a",{attrs:{href:"https://www.scribbledata.io/foundation-models-101-a-step-by-step-guide-for-beginners/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Foundation Models 101: A step-by-step guide for beginners"),a("OutboundLink")],1),t._v(" "),a("a",{staticClass:"footnote-backref",attrs:{href:"#footnote-ref2"}},[t._v("↩︎")])])]),t._v(" "),a("li",{staticClass:"footnote-item",attrs:{id:"footnote3"}},[a("p",[a("a",{attrs:{href:"https://www.nocode.ai/what-it-takes-to-train-a-foundation-model/",target:"_blank",rel:"noopener noreferrer"}},[t._v("What it Takes to Train a Foundation Model"),a("OutboundLink")],1),t._v(" "),a("a",{staticClass:"footnote-backref",attrs:{href:"#footnote-ref3"}},[t._v("↩︎")])])]),t._v(" "),a("li",{staticClass:"footnote-item",attrs:{id:"footnote4"}},[a("p",[a("a",{attrs:{href:"https://arxiv.org/abs/2108.07258",target:"_blank",rel:"noopener noreferrer"}},[t._v("On the Opportunities and Risks of Foundation Models(2021)"),a("OutboundLink")],1),t._v(" "),a("a",{staticClass:"footnote-backref",attrs:{href:"#footnote-ref4"}},[t._v("↩︎")]),t._v(" "),a("a",{staticClass:"footnote-backref",attrs:{href:"#footnote-ref4:1"}},[t._v("↩︎")]),t._v(" "),a("a",{staticClass:"footnote-backref",attrs:{href:"#footnote-ref4:2"}},[t._v("↩︎")])])])])])])}),[],!1,null,null,null);a.default=e.exports}}]);